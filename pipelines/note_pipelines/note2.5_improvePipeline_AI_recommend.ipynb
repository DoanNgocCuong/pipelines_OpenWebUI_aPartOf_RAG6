{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu **`page_content`** chính là **answer** trong trường hợp của bạn, thì bạn có thể đồng nhất việc sử dụng trường này làm câu trả lời trực tiếp khi tìm thấy tài liệu có độ tương đồng cao. Dưới đây là cách tối ưu pipeline để xử lý kịch bản này.\n",
    "\n",
    "---\n",
    "\n",
    "### Cách xử lý tối ưu:\n",
    "\n",
    "#### 1. **Cấu trúc dữ liệu trong Qdrant**\n",
    "Mỗi tài liệu trong Qdrant cần có:\n",
    "- `vector`: Biểu diễn vector hóa của nội dung tài liệu hoặc câu hỏi liên quan.\n",
    "- `payload`: \n",
    "  - `page_content`: Nội dung câu trả lời hoặc thông tin cần thiết.\n",
    "  - `metadata`: Thông tin bổ sung (như nguồn tài liệu, câu hỏi liên quan, v.v.).\n",
    "\n",
    "Ví dụ:\n",
    "```json\n",
    "{\n",
    "    \"id\": \"1\",\n",
    "    \"vector\": [0.123, 0.234, 0.345, ...],\n",
    "    \"payload\": {\n",
    "        \"page_content\": \"Luật này quy định về quy tắc giao thông đường bộ...\",\n",
    "        \"metadata\": {\n",
    "            \"source\": \"LegalRAG.xlsx\",\n",
    "            \"question\": \"Trình bày khái niệm, chế độ pháp lý vùng nội thủy...\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Hàm `pipe` được tối ưu hóa**\n",
    "Khi tìm thấy tài liệu có **`page_content`** với độ tương đồng cao, trả về nội dung ngay lập tức.\n",
    "\n",
    "```python\n",
    "def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Union[str, Generator, Iterator]:\n",
    "    \"\"\"Process user message and return relevant context\"\"\"\n",
    "    try:\n",
    "        print(f\"Processing: {user_message}\")\n",
    "\n",
    "        # Tạo embedding và tìm kiếm câu hỏi tương tự trong Qdrant\n",
    "        query_vector = self.embeddings.embed_query(user_message)\n",
    "        results = self.search_vectors(query_vector)\n",
    "\n",
    "        if \"error\" in results:\n",
    "            return f\"Search error: {results['error']}\"\n",
    "\n",
    "        matches = results.get(\"result\", [])\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                score = float(match.get(\"score\", 0))\n",
    "                payload = match.get(\"payload\", {})\n",
    "\n",
    "                # Trả về page_content trực tiếp nếu độ tương đồng >= 0.8\n",
    "                if score >= 0.8 and \"page_content\" in payload:\n",
    "                    return f\"Câu trả lời từ tài liệu: {payload['page_content']} (Nguồn: {payload.get('metadata', {}).get('source', 'Không rõ')})\"\n",
    "\n",
    "        # Nếu không tìm thấy, tạo câu trả lời qua OpenAI\n",
    "        print(\"Không tìm thấy tài liệu phù hợp, tạo câu trả lời qua OpenAI...\")\n",
    "        context = [\n",
    "            match.get(\"payload\", {}).get(\"page_content\", \"No content\")\n",
    "            for match in matches if match.get(\"score\", 0) > 0.5\n",
    "        ]\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"Bạn là trợ lý AI giúp trả lời các câu hỏi dựa trên tài liệu pháp lý. \"\n",
    "                    \"Dưới đây là ngữ cảnh:\\n\\n\" + \"\\n\\n\".join(context)\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = asyncio.run(self.get_completion(messages))\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Cập nhật hàm `search_vectors`**\n",
    "Tối ưu hàm tìm kiếm để đảm bảo `page_content` và `metadata` được trả về.\n",
    "\n",
    "```python\n",
    "def search_vectors(self, query_vector: List[float], top_k: int = 5) -> dict:\n",
    "    \"\"\"Search Qdrant collection\"\"\"\n",
    "    try:\n",
    "        payload = {\n",
    "            \"vector\": query_vector,\n",
    "            \"limit\": top_k,\n",
    "            \"with_payload\": True,  # Trả về payload chứa page_content và metadata\n",
    "            \"score_threshold\": 0.8\n",
    "        }\n",
    "\n",
    "        url = f\"{self.valves.QDRANT_API_URL}/collections/{self.valves.QDRANT_COLLECTION}/points/search\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.valves.QDRANT_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return {\"result\": response.json().get(\"result\", [])}\n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Kết quả đầu ra**\n",
    "- **Nếu tìm thấy câu hỏi tương đồng:** \n",
    "  ```plaintext\n",
    "  Câu trả lời từ tài liệu: Luật này quy định về quy tắc giao thông đường bộ... (Nguồn: LegalRAG.xlsx)\n",
    "  ```\n",
    "- **Nếu không tìm thấy:** \n",
    "  OpenAI sẽ được gọi để tạo câu trả lời dựa trên ngữ cảnh.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Tùy chọn mở rộng**\n",
    "- Bạn có thể bổ sung logic để trả về cả **câu hỏi gốc trong metadata** nhằm tăng tính trực quan:\n",
    "  ```python\n",
    "  return f\"Câu trả lời từ tài liệu: {payload['page_content']} (Nguồn: {payload.get('metadata', {}).get('source', 'Không rõ')}, Câu hỏi gốc: {payload.get('metadata', {}).get('question', 'Không rõ')})\"\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu **`page_content`** chính là **answer** trong trường hợp của bạn, thì bạn có thể đồng nhất việc sử dụng trường này làm câu trả lời trực tiếp khi tìm thấy tài liệu có độ tương đồng cao. Dưới đây là cách tối ưu pipeline để xử lý kịch bản này.\n",
    "\n",
    "---\n",
    "\n",
    "### Cách xử lý tối ưu:\n",
    "\n",
    "#### 1. **Cấu trúc dữ liệu trong Qdrant**\n",
    "Mỗi tài liệu trong Qdrant cần có:\n",
    "- `vector`: Biểu diễn vector hóa của nội dung tài liệu hoặc câu hỏi liên quan.\n",
    "- `payload`: \n",
    "  - `page_content`: Nội dung câu trả lời hoặc thông tin cần thiết.\n",
    "  - `metadata`: Thông tin bổ sung (như nguồn tài liệu, câu hỏi liên quan, v.v.).\n",
    "\n",
    "Ví dụ:\n",
    "```json\n",
    "{\n",
    "    \"id\": \"1\",\n",
    "    \"vector\": [0.123, 0.234, 0.345, ...],\n",
    "    \"payload\": {\n",
    "        \"page_content\": \"Luật này quy định về quy tắc giao thông đường bộ...\",\n",
    "        \"metadata\": {\n",
    "            \"source\": \"LegalRAG.xlsx\",\n",
    "            \"question\": \"Trình bày khái niệm, chế độ pháp lý vùng nội thủy...\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Hàm `pipe` được tối ưu hóa**\n",
    "Khi tìm thấy tài liệu có **`page_content`** với độ tương đồng cao, trả về nội dung ngay lập tức.\n",
    "\n",
    "```python\n",
    "def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Union[str, Generator, Iterator]:\n",
    "    \"\"\"Process user message and return relevant context\"\"\"\n",
    "    try:\n",
    "        print(f\"Processing: {user_message}\")\n",
    "\n",
    "        # Tạo embedding và tìm kiếm câu hỏi tương tự trong Qdrant\n",
    "        query_vector = self.embeddings.embed_query(user_message)\n",
    "        results = self.search_vectors(query_vector)\n",
    "\n",
    "        if \"error\" in results:\n",
    "            return f\"Search error: {results['error']}\"\n",
    "\n",
    "        matches = results.get(\"result\", [])\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                score = float(match.get(\"score\", 0))\n",
    "                payload = match.get(\"payload\", {})\n",
    "\n",
    "                # Trả về page_content trực tiếp nếu độ tương đồng >= 0.8\n",
    "                if score >= 0.8 and \"page_content\" in payload:\n",
    "                    return f\"Câu trả lời từ tài liệu: {payload['page_content']} (Nguồn: {payload.get('metadata', {}).get('source', 'Không rõ')})\"\n",
    "\n",
    "        # Nếu không tìm thấy, tạo câu trả lời qua OpenAI\n",
    "        print(\"Không tìm thấy tài liệu phù hợp, tạo câu trả lời qua OpenAI...\")\n",
    "        context = [\n",
    "            match.get(\"payload\", {}).get(\"page_content\", \"No content\")\n",
    "            for match in matches if match.get(\"score\", 0) > 0.5\n",
    "        ]\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"Bạn là trợ lý AI giúp trả lời các câu hỏi dựa trên tài liệu pháp lý. \"\n",
    "                    \"Dưới đây là ngữ cảnh:\\n\\n\" + \"\\n\\n\".join(context)\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = asyncio.run(self.get_completion(messages))\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Cập nhật hàm `search_vectors`**\n",
    "Tối ưu hàm tìm kiếm để đảm bảo `page_content` và `metadata` được trả về.\n",
    "\n",
    "```python\n",
    "def search_vectors(self, query_vector: List[float], top_k: int = 5) -> dict:\n",
    "    \"\"\"Search Qdrant collection\"\"\"\n",
    "    try:\n",
    "        payload = {\n",
    "            \"vector\": query_vector,\n",
    "            \"limit\": top_k,\n",
    "            \"with_payload\": True,  # Trả về payload chứa page_content và metadata\n",
    "            \"score_threshold\": 0.8\n",
    "        }\n",
    "\n",
    "        url = f\"{self.valves.QDRANT_API_URL}/collections/{self.valves.QDRANT_COLLECTION}/points/search\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.valves.QDRANT_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return {\"result\": response.json().get(\"result\", [])}\n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Kết quả đầu ra**\n",
    "- **Nếu tìm thấy câu hỏi tương đồng:** \n",
    "  ```plaintext\n",
    "  Câu trả lời từ tài liệu: Luật này quy định về quy tắc giao thông đường bộ... (Nguồn: LegalRAG.xlsx)\n",
    "  ```\n",
    "- **Nếu không tìm thấy:** \n",
    "  OpenAI sẽ được gọi để tạo câu trả lời dựa trên ngữ cảnh.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Tùy chọn mở rộng**\n",
    "- Bạn có thể bổ sung logic để trả về cả **câu hỏi gốc trong metadata** nhằm tăng tính trực quan:\n",
    "  ```python\n",
    "  return f\"Câu trả lời từ tài liệu: {payload['page_content']} (Nguồn: {payload.get('metadata', {}).get('source', 'Không rõ')}, Câu hỏi gốc: {payload.get('metadata', {}).get('question', 'Không rõ')})\"\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cấu trúc này đã tốt, nhưng tôi đề xuất một số điều chỉnh để tối ưu hơn:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"doc_1\",\n",
    "    \"vector\": [...],\n",
    "    \"payload\": {\n",
    "        \"page_content\": \"Luật này quy định về quy tắc giao thông đường bộ...\",\n",
    "        \"metadata\": {\n",
    "            \"source\": \"LegalRAG.xlsx\",\n",
    "            \"question\": \"Trình bày khái niệm, chế độ pháp lý vùng nội thủy...\",\n",
    "            \"chapter\": \"Chương 1\",           // Thêm thông tin phân loại\n",
    "            \"category\": \"Luật Giao thông\",   // Thêm danh mục\n",
    "            \"last_updated\": \"2024-01-01\"     // Thêm thông tin version\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Lý do đề xuất:\n",
    "\n",
    "1. **Cấu trúc hiện tại đã tốt vì**:\n",
    "   - Tách biệt rõ ràng giữa nội dung (`page_content`) và metadata\n",
    "   - Có thông tin nguồn (`source`)\n",
    "   - Có câu hỏi liên quan (`question`)\n",
    "\n",
    "2. **Có thể cải thiện bằng cách**:\n",
    "   - Thêm các trường metadata hữu ích\n",
    "   - Chuẩn hóa format câu hỏi\n",
    "   - Thêm các trường để dễ dàng tìm kiếm và lọc\n",
    "\n",
    "3. **Đề xuất format câu hỏi**:\n",
    "```python\n",
    "{\n",
    "    \"payload\": {\n",
    "        \"page_content\": \"Nội dung chi tiết...\",\n",
    "        \"metadata\": {\n",
    "            \"questions\": [  // Mảng các câu hỏi thay vì một câu\n",
    "                {\n",
    "                    \"text\": \"Trình bày khái niệm, chế độ pháp lý vùng nội thủy?\",\n",
    "                    \"type\": \"definition\",  // Loại câu hỏi\n",
    "                    \"keywords\": [\"khái niệm\", \"pháp lý\", \"nội thủy\"]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": {\n",
    "                \"file\": \"LegalRAG.xlsx\",\n",
    "                \"sheet\": \"Sheet1\",\n",
    "                \"row\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "4. **Code xử lý sẽ cần điều chỉnh**:\n",
    "```python:pipelines/qdant_pipeline_zohaibMeExtending.py\n",
    "def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Union[str, Generator, Iterator]:\n",
    "    try:\n",
    "        # Tìm kiếm câu hỏi trùng khớp\n",
    "        exact_match = self.qdrant_client.scroll(\n",
    "            collection_name=self.valves.QDRANT_COLLECTION,\n",
    "            scroll_filter=models.Filter(\n",
    "                must=[\n",
    "                    models.FieldCondition(\n",
    "                        key=\"metadata.questions.text\",  # Đường dẫn mới\n",
    "                        match=models.MatchValue(value=user_message.lower().strip())\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            limit=1\n",
    "        )\n",
    "        \n",
    "        if exact_match and len(exact_match[0]) > 0:\n",
    "            match = exact_match[0][0]\n",
    "            return {\n",
    "                \"answer\": match.payload.get('page_content', ''),\n",
    "                \"source\": match.payload.get('metadata', {}).get('source', {}).get('file', ''),\n",
    "                \"category\": match.payload.get('metadata', {}).get('category', '')\n",
    "            }\n",
    "            \n",
    "        # Tiếp tục xử lý vector search nếu không tìm thấy\n",
    "        # ...\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "```\n",
    "\n",
    "5. **Lợi ích của cấu trúc mới**:\n",
    "   - Dễ dàng mở rộng thêm thông tin metadata\n",
    "   - Hỗ trợ nhiều câu hỏi cho một nội dung\n",
    "   - Dễ dàng tìm kiếm và lọc theo nhiều tiêu chí\n",
    "   - Có thể thêm thông tin phiên bản và cập nhật\n",
    "   - Cấu trúc nguồn chi tiết hơn\n",
    "\n",
    "6. **Lưu ý khi triển khai**:\n",
    "   - Cần cập nhật code indexing để hỗ trợ cấu trúc mới\n",
    "   - Đảm bảo các trường metadata được index đúng cách\n",
    "   - Có thể cần migration data nếu đã có dữ liệu cũ\n",
    "\n",
    "Bạn nghĩ sao về những đề xuất này?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
