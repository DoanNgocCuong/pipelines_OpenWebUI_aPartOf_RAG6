{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tôi sẽ giải thích cách hoạt động của pipeline RAG (Retrieval Augmented Generation) này:\n",
    "\n",
    "1. **Khởi tạo và Cấu hình**:\n",
    "```python\n",
    "async def on_startup(self):\n",
    "    # Set OpenAI API key\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\"\n",
    "```\n",
    "\n",
    "2. **Tạo Document Store và Load Data**:\n",
    "```python\n",
    "# Tạo kho lưu trữ document trong bộ nhớ\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# Load dataset về 7 kỳ quan thế giới\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
    "```\n",
    "\n",
    "3. **Xử lý Embeddings**:\n",
    "```python\n",
    "# Tạo embeddings cho documents\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])\n",
    "\n",
    "# Tạo embedder cho câu hỏi của user\n",
    "text_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "```\n",
    "\n",
    "4. **Thiết lập Pipeline**:\n",
    "```python\n",
    "# Tạo retriever để tìm documents liên quan\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "\n",
    "# Template để tạo prompt\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Tạo generator sử dụng OpenAI\n",
    "generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n",
    "```\n",
    "\n",
    "5. **Kết nối các Components**:\n",
    "```python\n",
    "self.basic_rag_pipeline.connect(\n",
    "    \"text_embedder.embedding\", \"retriever.query_embedding\"\n",
    ")\n",
    "self.basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "self.basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "```\n",
    "\n",
    "6. **Xử lý Câu hỏi**:\n",
    "```python\n",
    "def pipe(self, user_message: str, ...):\n",
    "    response = self.basic_rag_pipeline.run({\n",
    "        \"text_embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "    })\n",
    "    return response[\"llm\"][\"replies\"][0]\n",
    "```\n",
    "\n",
    "**Luồng xử lý khi user đặt câu hỏi**:\n",
    "1. Câu hỏi được chuyển thành vector embedding\n",
    "2. Vector này được so sánh với embeddings của documents trong store\n",
    "3. Retriever tìm các documents liên quan nhất\n",
    "4. Documents này được đưa vào template làm context\n",
    "5. OpenAI sẽ trả lời dựa trên context và câu hỏi\n",
    "6. Trả kết quả về cho user\n",
    "\n",
    "Ví dụ:\n",
    "- User hỏi: \"Tell me about the Great Wall of China\"\n",
    "- Pipeline sẽ tìm documents liên quan đến Great Wall\n",
    "- OpenAI sẽ tổng hợp thông tin từ documents để trả lời\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
